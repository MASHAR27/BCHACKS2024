# -*- coding: utf-8 -*-
"""New Data.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1rgTh19t2GJEwyDHAcR8aMt5VGLTV2kEk
"""

# !wget file.weasoft.com/trans2.seq

import torch
import numpy as np

# !pip install wandb
device = 'cuda' if torch.cuda.is_available() else 'cpu'

DIM = 512
import math
import torch.nn as nn
class PositionalEncoding(nn.Module):

    def __init__(self, d_model: int, dropout: float = 0.1, max_len: int = 5000):
        super().__init__()
        self.dropout = nn.Dropout(p=dropout)

        position = torch.arange(max_len).unsqueeze(1)
        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))
        pe = torch.zeros(max_len, 1, d_model)
        pe[:, 0, 0::2] = torch.sin(position * div_term)
        pe[:, 0, 1::2] = torch.cos(position * div_term)
        self.register_buffer('pe', pe)

    def forward(self, x):
        """
        Arguments:
            x: Tensor, shape ``[seq_len, batch_size, embedding_dim]``
        """
        x = x + self.pe[:x.size(0)].to(device)
        return x
#https://pytorch.org/tutorials/beginner/transformer_tutorial.html

class Music(torch.nn.Module):
  def __init__(self):
    super().__init__()
    self.pos = PositionalEncoding(DIM, max_len=201)#torch.nn.Embedding(200, DIM).to(device)
    self.projection = torch.nn.Embedding(128, DIM).to(device)
    self.trans = torch.nn.TransformerEncoder(torch.nn.TransformerEncoderLayer(DIM, 16, batch_first=True), 8).to(device)
    self.output = torch.nn.Linear(DIM, 128).to(device)
  def forward(self, x):
    #pos = self.pos(torch.arange(0,200).to(device))
    feature = self.projection(x)
    feature = self.pos(feature)
    feature = self.trans(feature, mask=torch.nn.Transformer.generate_square_subsequent_mask(200), is_causal=True)
    return self.output(feature)
model = Music()
model(torch.rand(1,200).to(torch.int32).to(device)).shape

with open("trans2.seq","r") as f:
  data=[[int(j) for j in i.split(" ")[:200] if j!=""] for i in f.read().split("\n") if len(i.split(" "))>=200]

new_data = []
for i in data:
  if len(i)==200:
    new_data.append(i)

new_data = np.array(new_data)

new_data.shape

import pylab
pylab.hist((new_data).flatten())

!pip install wandb

import wandb
wandb.login()

run = wandb.init(
    project="ba-hacks",
)

BATCH_SIZE = 128

import random
def getdata():
  data = random.choices(new_data, k=BATCH_SIZE)
  data = np.array(data)
  return np.concatenate((np.zeros((BATCH_SIZE,1)),data[:,:-1]), axis=1), data

np.concatenate((np.zeros((10,1)),new_data[:10,:-1]), axis=1).shape

# c = FocalLoss(gamma=0.7)
# m = torch.nn.Softmax(dim=-1)
# def loss_fn(o, t):
#   return c(m(o),t)
loss_fn = torch.nn.CrossEntropyLoss()
optimizer = torch.optim.AdamW(model.parameters(), lr=7e-7)
scheduler =  torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, len(new_data)//BATCH_SIZE//10)

model = model.to(device)
runing_loss = 0
count = 0
for epoch in range(30):
  for i in range(len(new_data)//BATCH_SIZE):
    x, y = getdata()
    x, y = torch.tensor(x).to(device).to(torch.int32), torch.tensor(y).to(device).to(torch.int64)
    output = model(x)
    loss = loss_fn(output.permute(0,2,1), y)
    loss.backward()
    runing_loss += loss.item()
    count += 1
    if count==50:
      acc = torch.sum(torch.argmax(output, dim=-1)==y)/(200*128)
      wandb.log({"loss":runing_loss/50,"acc2":acc.item()})
      runing_loss = 0
      count = 0
    optimizer.step()
    scheduler.step()
  torch.save(model, "music.mod")

acc

pylab.bar(np.arange(128), torch.nn.Softmax()(output[0][0].cpu().detach()))

y.shape